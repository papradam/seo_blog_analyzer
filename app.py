import streamlit as st
import time
import pandas as pd
from index_check import limpiar_url, obtener_enlaces_internos, analizar_indexabilidad, clasificar_tipo_pagina
from contenido_repetido import extraer_bloques_editoriales
from analisis_seo import analizar_texto
from rapidfuzz import fuzz

st.set_page_config(page_title="AnÃ¡lisis de Indexabilidad", layout="wide")
st.title("ğŸ” AnÃ¡lisis de Indexabilidad de URLs")

url_blog = st.text_input("ğŸ“ URL del blog principal")

# Estado inicial
if 'estado' not in st.session_state:
    st.session_state.estado = 'inicio'
if 'modo_contenido' not in st.session_state:
    st.session_state.modo_contenido = False
if 'url_listado' not in st.session_state:
    st.session_state.url_listado = []
if 'contenido_variable' not in st.session_state:
    st.session_state.contenido_variable = {}
if 'resultados_seo' not in st.session_state:
    st.session_state.resultados_seo = {}
if 'texto_analizado_por_url' not in st.session_state:
    st.session_state.texto_analizado_por_url = {}
if 'html_analizado_por_url' not in st.session_state:
    st.session_state.html_analizado_por_url = {}

# BotÃ³n de inicio
if st.session_state.estado == 'inicio':
    if st.button("ğŸš€ Iniciar proceso") and url_blog:
        st.session_state.estado = 'activo'
        st.session_state.modo_contenido = False
        st.session_state.url_listado = [{
            "url": limpiar_url(url_blog),
            "estado": "pendiente",
            "indexable": None,
            "codigo": None,
            "canonicals": [],
            "robots": None,
            "tipo_pagina": "home"
        }]
        st.rerun()
else:
    # Botones de control
    col1, col2 = st.columns(2)
    with col1:
        label = "â¸ Pausar proceso" if st.session_state.estado == 'activo' else "â–¶ Reanudar proceso"
        if st.button(label):
            st.session_state.estado = 'pausado' if st.session_state.estado == 'activo' else 'activo'
            st.rerun()

    with col2:
        indexables = [
            u for u in st.session_state.url_listado
            if u['estado'] == 'evaluado' and u['indexable'] and u.get('tipo_pagina') == 'contenido'
        ]
        if len(indexables) >= 3:
            label = "â¸ Pausar anÃ¡lisis de contenido" if st.session_state.modo_contenido else "ğŸ§  Evaluar contenido de valor"
            if st.button(label):
                if st.session_state.modo_contenido:
                    st.session_state.modo_contenido = False
                    st.session_state.estado = 'activo'
                else:
                    st.session_state.modo_contenido = True
                    st.session_state.estado = 'pausado'

                    # Detectar bloques repetidos entre 3 URLs
                    urls_para_comparar = [u['url'] for u in indexables[:3]]
                    bloques_por_url = {
                        url: extraer_bloques_editoriales(url)
                        for url in urls_para_comparar
                    }

                    bloques_repetidos = set()
                    for i in range(3):
                        for j in range(i + 1, 3):
                            for b1 in bloques_por_url[urls_para_comparar[i]]:
                                for b2 in bloques_por_url[urls_para_comparar[j]]:
                                    if fuzz.token_set_ratio(b1["texto"], b2["texto"]) >= 90:
                                        bloques_repetidos.add(b1["texto"])
                                        bloques_repetidos.add(b2["texto"])

                    # Aplicar filtrado a todas las URLs vÃ¡lidas
                    st.session_state.contenido_variable = {}
                    for u in indexables:
                        todos_bloques = extraer_bloques_editoriales(u['url'])
                        bloques_unicos = [b for b in todos_bloques if b["html"] not in {x["html"] for url in urls_para_comparar for x in bloques_por_url[url] if x["texto"] in bloques_repetidos}]
                        if bloques_unicos:
                            st.session_state.contenido_variable[u['url']] = bloques_unicos

                st.rerun()

# Mostrar progreso
if st.session_state.estado != 'inicio' and not st.session_state.modo_contenido:
    total = len(st.session_state.url_listado)
    evaluadas = len([u for u in st.session_state.url_listado if u['estado'] == 'evaluado'])
    pendientes = total - evaluadas

    st.markdown("### ğŸ“Š Progreso del anÃ¡lisis")
    st.progress(evaluadas / total if total else 0.0)
    st.markdown(f"**URLs evaluadas:** {evaluadas}")
    st.markdown(f"**URLs pendientes:** {pendientes}")
    st.markdown(f"**Total de URLs:** {total}")

    st.markdown("### ğŸ“„ URLs encontradas")

    datos = [{
        "Ãndice": i + 1,
        "URL": item["url"],
        "Estado": item["estado"],
        "Indexable": "âœ…" if item.get("indexable") else ("âŒ" if item.get("indexable") is False else "â³"),
        "Tipo de pÃ¡gina": item.get("tipo_pagina", "desconocido")
    } for i, item in enumerate(st.session_state.url_listado)]

    st.dataframe(pd.DataFrame(datos).set_index("Ãndice"), use_container_width=True)

# Proceso de indexabilidad
if st.session_state.estado == 'activo':
    for registro in st.session_state.url_listado:
        if registro['estado'] == 'pendiente':
            url_actual = limpiar_url(registro['url'])
            registro['estado'] = 'evaluado'
            codigo, canonicals, robots, indexable = analizar_indexabilidad(url_actual)
            registro['indexable'] = indexable
            registro['codigo'] = codigo
            registro['canonicals'] = canonicals
            registro['robots'] = robots

            if indexable:
                nuevos = obtener_enlaces_internos(url_actual, url_blog)
                for nueva_url in nuevos:
                    nueva_url_limpia = limpiar_url(nueva_url)
                    if not any(u['url'] == nueva_url_limpia for u in st.session_state.url_listado):
                        st.session_state.url_listado.append({
                            "url": nueva_url_limpia,
                            "estado": "pendiente",
                            "indexable": None,
                            "codigo": None,
                            "canonicals": [],
                            "robots": None,
                            "tipo_pagina": clasificar_tipo_pagina(nueva_url_limpia)
                        })
            break
    time.sleep(0.3)
    st.rerun()

# Proceso de evaluaciÃ³n de contenido de valor
if st.session_state.modo_contenido:
    urls_restantes = list(st.session_state.contenido_variable.keys())
    if urls_restantes:
        siguiente = urls_restantes[0]
        bloques = st.session_state.contenido_variable[siguiente]

        texto = "\n\n".join([b["texto"] for b in bloques]).strip()
        html = "".join([b["html"] for b in bloques]).strip()

        if texto:
            resultado = analizar_texto(texto, html)
            st.session_state.resultados_seo[siguiente] = resultado
            st.session_state.texto_analizado_por_url[siguiente] = texto
            st.session_state.html_analizado_por_url[siguiente] = html
        else:
            st.warning(f"El contenido de `{siguiente}` estÃ¡ vacÃ­o o fue totalmente filtrado.")

        del st.session_state.contenido_variable[siguiente]
        time.sleep(0.3)
        st.rerun()

# Mostrar mÃ©tricas si hay resultados SEO analizados
if st.session_state.resultados_seo:
    st.sidebar.markdown("## ğŸ”— Selecciona una URL")
    seleccion = st.sidebar.radio(
        "URLs con anÃ¡lisis semÃ¡ntico",
        list(st.session_state.resultados_seo.keys())
    )

    if seleccion:
        st.markdown(f"## ğŸ“Š Detalle SEO para: `{seleccion}`")
        res = st.session_state.resultados_seo[seleccion]

        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“– Legibilidad", f"{res['indice_legibilidad']:.2f}")
            st.metric("ğŸ“ Nivel educativo", res['nivel_educativo'])

        with col2:
            st.metric("ğŸ“ Palabras", res['num_palabras'])
            st.metric("ğŸ“„ PÃ¡rrafos", res['num_parrafos'])

        st.markdown("### ğŸ” Palabras clave extraÃ­das")
        for frase, count in res['palabras_clave']:
            st.write(f"- {frase} ({count})")

        # Mostrar contenido analizado como HTML renderizado
        if seleccion in st.session_state.html_analizado_por_url:
            with st.expander("ğŸ—¾ Contenido analizado (HTML renderizado)"):
                html = st.session_state.html_analizado_por_url.get(seleccion, "")
                st.markdown(html, unsafe_allow_html=True)
